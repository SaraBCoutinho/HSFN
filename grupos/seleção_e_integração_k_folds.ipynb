{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jNBqH-tnRp2"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1VDeNNqThX8J"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.lines as mlines\n",
        "from statistics import pstdev, mean\n",
        "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
        "from sklearn.metrics import f1_score, accuracy_score,precision_score, recall_score,roc_auc_score\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix, log_loss\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.manifold import MDS, TSNE\n",
        "!pip install deslib\n",
        "from deslib.util.diversity import double_fault\n",
        "import scipy.stats as stats\n",
        "from scipy.cluster import hierarchy\n",
        "from scipy.cluster.hierarchy import average, fcluster, dendrogram, ward, single, linkage\n",
        "!pip install umap\n",
        "!pip install umap-learn\n",
        "!pip install 'umap-learn==0.3.10'\n",
        "from umap.umap_ import UMAP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9Zaiv9upV_-"
      },
      "source": [
        "## Funções"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O-iKHxu3pXoK"
      },
      "outputs": [],
      "source": [
        "def filter_df_train_test(train_df, test_df, name, filter_first=True):\n",
        "    train = train_df.filter(regex=name, axis=1)\n",
        "    test = test_df.filter(regex=name, axis=1)\n",
        "    return train.to_numpy(), test.to_numpy(), train.columns\n",
        "\n",
        "def filter_collinearity(X_train, X_test):\n",
        "    X_train = X_train[:, ::2]\n",
        "    X_test = X_test[:, ::2]\n",
        "    return X_train, X_test\n",
        "\n",
        "def create_coefficient_plot(coefs, names, group, savename):\n",
        "    log_odds = np.exp(coefs.T)\n",
        "    log_odds = pd.DataFrame(log_odds,names,['Coef']).sort_values(by='Coef', ascending=False)\n",
        "    log_odds.round(3)\n",
        "    log_odds.plot.bar()\n",
        "    plt.ylabel('Coefficients')\n",
        "    plt.xlabel(group)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(savename+'.pdf', dpi=300)\n",
        "def organize_names_df(names):\n",
        "    names_coeffs = names[::2]\n",
        "    names_coeffs = [name.replace(\"-0\", \"\") for name in names_coeffs]\n",
        "    return names_coeffs\n",
        "\n",
        "stackingLR = ['LR',LogisticRegression(class_weight='balanced',multi_class='multinomial')]\n",
        "stackingRF = ['RF',RandomForestClassifier(class_weight='balanced')]\n",
        "stackingNB = ['NB',GaussianNB()]\n",
        "\n",
        "def conditions_name_stacking(stacking):\n",
        "  name=''\n",
        "  if stacking==stackingLR[1]:\n",
        "    name='LR'\n",
        "  elif stacking==stackingRF[1]:\n",
        "    name='RF'\n",
        "  elif stacking==stackingNB[1]:\n",
        "    name='NB'\n",
        "  return name\n",
        "\n",
        "def conditions_name_metric(metric):\n",
        "  name=''\n",
        "  if metric==accuracy_score:\n",
        "    name='accuracy_score'\n",
        "  elif metric==recall_score:\n",
        "    name='recall_score'\n",
        "  elif metric==precision_score:\n",
        "    name='precision_score'\n",
        "  elif metric==f1_score:\n",
        "    name='f1_score'\n",
        "  return name\n",
        "\n",
        "def stackingA(stacking,metric):\n",
        "  algorithms_list = ['SVM', 'LR','RF','NB','MLP', 'EXTRA','KNN','CNN']\n",
        "  results_A = np.zeros(len(algorithms_list))\n",
        "  for idx_alg, algorithm in enumerate(algorithms_list):\n",
        "    X_val, X_test, cols = filter_df_train_test(probas_val, probas_test, algorithm)\n",
        "    X_val, X_test = filter_collinearity(X_val, X_test)\n",
        "    stacking.fit(X_val, labels_val)\n",
        "    y_pred = stacking.predict(X_test)\n",
        "    score = round(metric(labels_test, y_pred),3)\n",
        "    stack=conditions_name_stacking(stacking)\n",
        "    name=conditions_name_metric(metric)\n",
        "    results_A[idx_alg] = score\n",
        "  return results_A\n",
        "\n",
        "def stackingB(stacking,metric):\n",
        "  fe_list = ['CV', 'TFIDF', 'W2V', 'GLOVE', 'FAST']\n",
        "  results_B = np.zeros(len(fe_list))\n",
        "  for idx_alg, fe in enumerate(fe_list):\n",
        "    X_val, X_test, cols = filter_df_train_test(probas_val, probas_test, fe)\n",
        "    X_val, X_test = filter_collinearity(X_val, X_test)\n",
        "    stacking.fit(X_val, labels_val)\n",
        "    y_pred = stacking.predict(X_test)\n",
        "    results_B[idx_alg] = round(metric(labels_test, y_pred),3)\n",
        "    stack=conditions_name_stacking(stacking)\n",
        "    name=conditions_name_metric(metric)\n",
        "  return results_B\n",
        "\n",
        "def stackingC(stacking,metric):\n",
        "  results_C = 0\n",
        "  X_val, X_test = filter_collinearity(probas_val.to_numpy(), probas_test.to_numpy())\n",
        "  stacking.fit(X_val, labels_val)\n",
        "  y_pred = stacking.predict(X_test)\n",
        "  results_C = round(metric(labels_test, y_pred),3)\n",
        "  stack=conditions_name_stacking(stacking)\n",
        "  name=conditions_name_metric(metric)\n",
        "  return results_C\n",
        "\n",
        "def compute_pairwise_diversity_matrix(targets, prediction_matrix, diversity_func):\n",
        "    n_classifiers = prediction_matrix.shape[1]\n",
        "    diversity = np.zeros((n_classifiers, n_classifiers))\n",
        "    for clf_index in range(n_classifiers):\n",
        "        for clf_index2 in range(clf_index + 1, n_classifiers):\n",
        "            this_diversity = diversity_func(targets,prediction_matrix[:, clf_index],\n",
        "                                            prediction_matrix[:, clf_index2])\n",
        "            diversity[clf_index, clf_index2] = this_diversity\n",
        "            diversity[clf_index2, clf_index] = this_diversity\n",
        "    return diversity\n",
        "\n",
        "def load_predictions(dataset_name,path):\n",
        "    table_pred = pd.read_csv(path)\n",
        "    print(dataset_name)\n",
        "    if dataset_name == 'fakes':\n",
        "        label = table_pred[\"label\"]\n",
        "        methods = table_pred.drop('label', axis=1)\n",
        "    methods = methods.drop('Unnamed: 0', axis=1)\n",
        "    methods = methods.drop('Unnamed: 0.1', axis=1)\n",
        "    return label, methods\n",
        "\n",
        "def Elbow_method_graph(z,total_clusters,fold):\n",
        "  last = z[-total_clusters:, 2]\n",
        "  last_rev = last[::-1]\n",
        "  idxs = np.arange(1, len(last) + 1)\n",
        "  #plt.plot(idxs, last_rev)\n",
        "  acceleration = np.diff(last, 2)\n",
        "  acceleration_rev = acceleration[::-1]\n",
        "  k = acceleration_rev.argmax() + 2\n",
        "  return(print(\"k clusters - elbow:\", k))\n",
        "\n",
        "def plot_diversity(D_changed, method_tmp, dataset_name, title):\n",
        "    s, colors, markers = 100, {}, {}\n",
        "    colors[0],colors[1],colors[2],colors[3],colors[4] = '#DAA520','#FF0000','#0000FF','#228B22','#000000'\n",
        "    markers[0], markers[1], markers[2], markers[3], markers[4]= 'X','d','*',\"^\",'o'\n",
        "    n_classifiers, n_features, _ = D_changed.shape\n",
        "    plt.figure(figsize=(15,10))\n",
        "    method=0\n",
        "    for idx in range(n_classifiers):\n",
        "        for idx2 in range(n_features):\n",
        "            x, y = D_changed[idx,idx2, 0], D_changed[idx,idx2, 1]\n",
        "            plt.scatter(x, y, color=colors[idx2], s=s, lw=0, marker=markers[idx2])\n",
        "            plt.annotate(method_tmp[method], xy=(x, y), textcoords='offset points', xytext=(5, 15), ha='right', va='top')\n",
        "            method += 1\n",
        "    m1 = mlines.Line2D([], [], color=colors[0], marker=markers[0], linestyle='None', markersize=10, label='CV')\n",
        "    m2 = mlines.Line2D([], [], color=colors[1], marker=markers[1], linestyle='None', markersize=10, label='TFIDF')\n",
        "    m3 = mlines.Line2D([], [], color=colors[2], marker=markers[2], linestyle='None', markersize=10, label='Glove')\n",
        "    m4 = mlines.Line2D([], [], color=colors[3], marker=markers[3], linestyle='None', markersize=10, label='Word2Vec')\n",
        "    m5 = mlines.Line2D([], [], color=colors[4], marker=markers[4], linestyle='None', markersize=10, label='FastText')\n",
        "    plt.title('CPS ' + dataset_name.upper()+' dataset')\n",
        "    plt.legend(handles=[m1, m2, m3, m4, m5])\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(title + \"_\" + dataset_name.upper() +'_dataset.jpg', dpi=450)\n",
        "\n",
        "def compute_matrix_embedding(dataset_name, n_classifiers, n_features, method, n_neighbors=5, min_dist=0.7):\n",
        "    label,methods=load_predictions(dataset_name,path)\n",
        "    D = compute_pairwise_diversity_matrix(label.to_numpy(), methods.to_numpy(), double_fault)\n",
        "    D = 1/D\n",
        "    D[D==np.inf] = 0\n",
        "    if method == 'mds':\n",
        "        method = MDS(dissimilarity='precomputed', random_state=123456987, n_init=20, max_iter=100000)\n",
        "    elif method == 'tsne':\n",
        "        method = TSNE(perplexity=25, init='pca', random_state=42, early_exaggeration=50,\n",
        "                      learning_rate=200, n_iter=2500, angle=0.5)\n",
        "    else:\n",
        "        method = UMAP(n_neighbors=2, metric='euclidean', random_state=123456987, min_dist=0.7, n_components=2,)\n",
        "    D_tilde = method.fit_transform(D)\n",
        "    D_tilde = D_tilde.reshape(n_classifiers, n_features, 2)\n",
        "    return D_tilde\n",
        "\n",
        "def plot_graph(table_pred,stacking,metric):\n",
        "  acc_cortes=[]\n",
        "  for i in range(1,41): #vai do 1 ao 40 no experimento\n",
        "    a,b=stack_D_Hierarchical(k=i,table_pred=table_pred,stacking=stacking,metric=metric)\n",
        "    acc_cortes.append(a)\n",
        "  X_plot=pd.DataFrame(acc_cortes)[1]\n",
        "  y_plot=pd.DataFrame(acc_cortes)[0]\n",
        "  return X_plot,y_plot\n",
        "\n",
        "lista_1=['CNN-CV','KNN-W2V','KNN-FAST','CNN-GLOVE','CNN-FAST','CNN-TFIDF','CNN-W2V','MLP-FAST','EXTRA-CV',\n",
        "         'EXTRA-TFIDF','EXTRA-GLOVE','KNN-TFIDF','KNN-GLOVE','KNN-CV','EXTRA-W2V','EXTRA-FAST','NB-FAST',\n",
        "         'MLP-CV','MLP-TFIDF','MLP-GLOVE','MLP-W2V','NB-CV','RF-W2V','RF-FAST','NB-W2V','NB-TFIDF','NB-GLOVE',\n",
        "         'SVM-W2V','SVM-GLOVE','SVM-CV','SVM-TFIDF','RF-TFIDF','RF-GLOVE','LR-FAST','RF-CV','SVM-FAST','LR-CV',\n",
        "         'LR-W2V','LR-TFIDF','LR-GLOVE']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrdn2QX2E2nx"
      },
      "source": [
        "## Classificadores monolíticos e grupos A, B e C"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DMirRb82WjWR"
      },
      "outputs": [],
      "source": [
        "!mkdir Data/kaggle/F1/accuracy_score\n",
        "!mkdir Data/kaggle/F1/precision_score\n",
        "!mkdir Data/kaggle/F1/recall_score\n",
        "!mkdir Data/kaggle/F1/f1_score\n",
        "!mkdir Data/kaggle/F1/roc_auc_score\n",
        "!mkdir Data/kaggle/F2/accuracy_score\n",
        "!mkdir Data/kaggle/F2/precision_score\n",
        "!mkdir Data/kaggle/F2/recall_score\n",
        "!mkdir Data/kaggle/F2/f1_score\n",
        "!mkdir Data/kaggle/F2/roc_auc_score\n",
        "!mkdir Data/kaggle/F3/accuracy_score\n",
        "!mkdir Data/kaggle/F3/precision_score\n",
        "!mkdir Data/kaggle/F3/recall_score\n",
        "!mkdir Data/kaggle/F3/f1_score\n",
        "!mkdir Data/kaggle/F3/roc_auc_score\n",
        "!mkdir Data/kaggle/F4/accuracy_score\n",
        "!mkdir Data/kaggle/F4/precision_score\n",
        "!mkdir Data/kaggle/F4/recall_score\n",
        "!mkdir Data/kaggle/F4/f1_score\n",
        "!mkdir Data/kaggle/F4/roc_auc_score\n",
        "!mkdir Data/kaggle/F5/accuracy_score\n",
        "!mkdir Data/kaggle/F5/precision_score\n",
        "!mkdir Data/kaggle/F5/recall_score\n",
        "!mkdir Data/kaggle/F5/f1_score\n",
        "!mkdir Data/kaggle/F5/roc_auc_score\n",
        "!mkdir Data/kaggle/F6/accuracy_score\n",
        "!mkdir Data/kaggle/F6/precision_score\n",
        "!mkdir Data/kaggle/F6/recall_score\n",
        "!mkdir Data/kaggle/F6/f1_score\n",
        "!mkdir Data/kaggle/F6/roc_auc_score\n",
        "!mkdir Data/kaggle/F7/accuracy_score\n",
        "!mkdir Data/kaggle/F7/precision_score\n",
        "!mkdir Data/kaggle/F7/recall_score\n",
        "!mkdir Data/kaggle/F7/f1_score\n",
        "!mkdir Data/kaggle/F7/roc_auc_score\n",
        "!mkdir Data/kaggle/F8/accuracy_score\n",
        "!mkdir Data/kaggle/F8/precision_score\n",
        "!mkdir Data/kaggle/F8/recall_score\n",
        "!mkdir Data/kaggle/F8/f1_score\n",
        "!mkdir Data/kaggle/F8/roc_auc_score\n",
        "!mkdir Data/kaggle/F9/accuracy_score\n",
        "!mkdir Data/kaggle/F9/precision_score\n",
        "!mkdir Data/kaggle/F9/recall_score\n",
        "!mkdir Data/kaggle/F9/f1_score\n",
        "!mkdir Data/kaggle/F9/roc_auc_score\n",
        "!mkdir Data/kaggle/F10/accuracy_score\n",
        "!mkdir Data/kaggle/F10/precision_score\n",
        "!mkdir Data/kaggle/F10/recall_score\n",
        "!mkdir Data/kaggle/F10/f1_score\n",
        "!mkdir Data/kaggle/F10/roc_auc_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kuM-2LiELCd-"
      },
      "outputs": [],
      "source": [
        "Columns_table=['SVM-CV', 'SVM-TFIDF', 'SVM-W2V', 'SVM-GLOVE','SVM-FAST', 'LR-CV', 'LR-TFIDF',\n",
        "               'LR-GLOVE', 'LR-W2V', 'LR-FAST','RF-CV', 'RF-TFIDF', 'RF-GLOVE', 'RF-W2V','RF-FAST',\n",
        "               'NB-CV','NB-TFIDF', 'NB-GLOVE', 'NB-W2V', 'NB-FAST', 'MLP-CV', 'MLP-TFIDF','MLP-GLOVE',\n",
        "               'MLP-W2V', 'MLP-FAST', 'EXTRA-CV', 'EXTRA-TFIDF','EXTRA-GLOVE', 'EXTRA-W2V', 'EXTRA-FAST',\n",
        "               'KNN-CV', 'KNN-TFIDF','KNN-GLOVE', 'KNN-W2V', 'KNN-FAST', 'CNN-CV', 'CNN-TFIDF', 'CNN-W2V','CNN-GLOVE', 'CNN-FAST']\n",
        "\n",
        "for fold in [\"F1\", \"F2\", \"F3\", \"F4\", \"F5\",\"F6\", \"F7\", \"F8\", \"F9\", \"F10\"]:\n",
        "  Results_table=pd.DataFrame(index=['P'],columns=Columns_table)\n",
        "  Results_table.to_csv('/content/Data/'+ dataset_name + '/' + fold + '/results_table.csv')\n",
        "\n",
        "#funçao para salvar resultados grupos A/B/C\n",
        "def saving_results_test_groups(Results_table,item,metric,fold):\n",
        "  Results_table.at[item,'A-SVM-LR']=stackingA(stackingLR[1],metric)[0]\n",
        "  Results_table.at[item,'A-LR-LR']=stackingA(stackingLR[1],metric)[1]\n",
        "  Results_table.at[item,'A-RF-LR']=stackingA(stackingLR[1],metric)[2]\n",
        "  Results_table.at[item,'A-NB-LR']=stackingA(stackingLR[1],metric)[3]\n",
        "  Results_table.at[item,'A-MLP-LR']=stackingA(stackingLR[1],metric)[4]\n",
        "  Results_table.at[item,'A-EXTRA-LR']=stackingA(stackingLR[1],metric)[5]\n",
        "  Results_table.at[item,'A-KNN-LR']=stackingA(stackingLR[1],metric)[6]\n",
        "  Results_table.at[item,'A-CNN-LR']=stackingA(stackingLR[1],metric)[7]\n",
        "  Results_table.at[item,'A-SVM-RF']=stackingA(stackingRF[1],metric)[0]\n",
        "  Results_table.at[item,'A-LR-RF']=stackingA(stackingRF[1],metric)[1]\n",
        "  Results_table.at[item,'A-RF-RF']=stackingA(stackingRF[1],metric)[2]\n",
        "  Results_table.at[item,'A-NB-RF']=stackingA(stackingRF[1],metric)[3]\n",
        "  Results_table.at[item,'A-MLP-RF']=stackingA(stackingRF[1],metric)[4]\n",
        "  Results_table.at[item,'A-EXTRA-RF']=stackingA(stackingRF[1],metric)[5]\n",
        "  Results_table.at[item,'A-KNN-RF']=stackingA(stackingRF[1],metric)[6]\n",
        "  Results_table.at[item,'A-CNN-RF']=stackingA(stackingRF[1],metric)[7]\n",
        "  Results_table.at[item,'A-SVM-NB']=stackingA(stackingNB[1],metric)[0]\n",
        "  Results_table.at[item,'A-LR-NB']=stackingA(stackingNB[1],metric)[1]\n",
        "  Results_table.at[item,'A-RF-NB']=stackingA(stackingNB[1],metric)[2]\n",
        "  Results_table.at[item,'A-NB-NB']=stackingA(stackingNB[1],metric)[3]\n",
        "  Results_table.at[item,'A-MLP-NB']=stackingA(stackingNB[1],metric)[4]\n",
        "  Results_table.at[item,'A-EXTRA-NB']=stackingA(stackingNB[1],metric)[5]\n",
        "  Results_table.at[item,'A-KNN-NB']=stackingA(stackingNB[1],metric)[6]\n",
        "  Results_table.at[item,'A-CNN-NB']=stackingA(stackingNB[1],metric)[7]\n",
        "  Results_table.at[item,'B-CV-LR']=stackingB(stackingLR[1],metric)[0]\n",
        "  Results_table.at[item,'B-TFIDF-LR']=stackingB(stackingLR[1],metric)[1]\n",
        "  Results_table.at[item,'B-W2V-LR']=stackingB(stackingLR[1],metric)[2]\n",
        "  Results_table.at[item,'B-GLOVE-LR']=stackingB(stackingLR[1],metric)[3]\n",
        "  Results_table.at[item,'B-FAST-LR']=stackingB(stackingLR[1],metric)[4]\n",
        "  Results_table.at[item,'B-CV-RF']=stackingB(stackingRF[1],metric)[0]\n",
        "  Results_table.at[item,'B-TFIDF-RF']=stackingB(stackingRF[1],metric)[1]\n",
        "  Results_table.at[item,'B-W2V-RF']=stackingB(stackingRF[1],metric)[2]\n",
        "  Results_table.at[item,'B-GLOVE-RF']=stackingB(stackingRF[1],metric)[3]\n",
        "  Results_table.at[item,'B-FAST-RF']=stackingB(stackingRF[1],metric)[4]\n",
        "  Results_table.at[item,'B-CV-NB']=stackingB(stackingNB[1],metric)[0]\n",
        "  Results_table.at[item,'B-TFIDF-NB']=stackingB(stackingNB[1],metric)[1]\n",
        "  Results_table.at[item,'B-W2V-NB']=stackingB(stackingNB[1],metric)[2]\n",
        "  Results_table.at[item,'B-GLOVE-NB']=stackingB(stackingNB[1],metric)[3]\n",
        "  Results_table.at[item,'B-FAST-NB']=stackingB(stackingNB[1],metric)[4]\n",
        "  Results_table.at[item,'C-LR']=stackingC(stackingLR[1],metric)\n",
        "  Results_table.at[item,'C-RF']=stackingC(stackingRF[1],metric)\n",
        "  Results_table.at[item,'C-NB']=stackingC(stackingNB[1],metric)\n",
        "  return Results_table\n",
        "\n",
        "files=[]\n",
        "for fold in [\"F1\", \"F2\", \"F3\", \"F4\", \"F5\",\"F6\", \"F7\", \"F8\", \"F9\", \"F10\"]:\n",
        "  files.append('/content/Data/'+ dataset_name + '/' + fold + '/pred_test.csv')\n",
        "#files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QK9mahScINab"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "#classificadores monolíticos, grupo A, grupo B e grupo C\n",
        "def saving_results_test(files,Results_table,metric,dataset_name,fold):\n",
        "  lista_table=[]\n",
        "  for element in files:\n",
        "    table=pd.read_csv(element)\n",
        "    table=table.drop(columns=['Unnamed: 0','Unnamed: 0.1'])\n",
        "    label_list=np.array(table['label'])\n",
        "    for column in table.columns:\n",
        "      pred_list=np.array(table[column])\n",
        "      lista_table.append([round(metric(label_list,pred_list),3),column])\n",
        "    for column in Results_table:\n",
        "      for i in range(len(lista_table)):\n",
        "        if column == lista_table[i][1] and element=='/content/Data/'+dataset_name+'/'+fold+'/pred_test.csv':\n",
        "          Results_table.at['P', column]=lista_table[i][0]\n",
        "  return Results_table\n",
        "\n",
        "for fold in [\"F1\", \"F2\", \"F3\", \"F4\", \"F5\",\"F6\", \"F7\", \"F8\", \"F9\", \"F10\"]:\n",
        "  train_labels=pd.read_csv('/content/Data/'+dataset_name+'/'+fold+'/train_labels.csv')\n",
        "  val_labels=pd.read_csv('/content/Data/'+dataset_name+'/'+fold+'/val_labels.csv')\n",
        "  test_labels=pd.read_csv('/content/Data/'+dataset_name+'/'+fold+'/test_labels.csv')\n",
        "  val_df = pd.read_csv('/content/Data/'+dataset_name+'/'+fold+'/prob_val.csv').dropna()\n",
        "  test_df = pd.read_csv('/content/Data/'+dataset_name+'/'+fold+'/prob_test.csv').dropna()\n",
        "  probas_val, labels_val = val_df.drop(columns=[\"Unnamed: 0\",\"Unnamed: 0.1\",\"label\"]), val_labels[\"label\"]\n",
        "  probas_test, labels_test = test_df.drop(columns=[\"Unnamed: 0\",\"Unnamed: 0.1\",\"label\"]), test_labels[\"label\"]\n",
        "\n",
        "  for metric in [accuracy_score,precision_score,recall_score,f1_score,roc_auc_score]:\n",
        "    path='./Data/'+dataset_name+'/'+fold+'/'+ str(conditions_name_metric(metric))\n",
        "    results_test_monolithcs=saving_results_test(files,Results_table,metric,dataset_name,fold)\n",
        "    results_test_monolithcs.to_csv('{}/results_test_monolithcs.csv'.format(path))\n",
        "\n",
        "    Results_table=saving_results_test(files,Results_table,metric,dataset_name,fold)\n",
        "    Results_table2=Results_table.copy()\n",
        "    Results_table2=saving_results_test_groups(Results_table=Results_table2,item='P',metric=metric,fold=fold)\n",
        "    Results_table2.to_csv('{}/Results_table2.csv'.format(path))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ep8uFJMQ4KKt"
      },
      "source": [
        "## Grupo D (Agrupamento Hierárquico)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0enrP6jKI5HO"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "for fold in [\"F1\", \"F2\", \"F3\", \"F4\", \"F5\",\"F6\", \"F7\", \"F8\", \"F9\", \"F10\"]:\n",
        "  train_labels = pd.read_csv('/content/Data/'+dataset_name+'/'+fold+'/train_labels.csv')\n",
        "  val_labels = pd.read_csv('/content/Data/'+dataset_name+'/'+fold+'/val_labels.csv')\n",
        "  test_labels = pd.read_csv('/content/Data/'+dataset_name+'/'+fold+'/test_labels.csv')\n",
        "  val_df = pd.read_csv('/content/Data/'+dataset_name+'/'+fold+'/val.csv')\n",
        "  test_df = pd.read_csv('/content/Data/'+dataset_name+'/'+fold+'/test.csv')\n",
        "  probas_val, labels_val = val_df.drop(columns=[\"Unnamed: 0\",\"Unnamed: 0.1\",\"label\"]), val_labels[\"label\"]\n",
        "  probas_test, labels_test = test_df.drop(columns=[\"Unnamed: 0\",\"Unnamed: 0.1\",\"label\"]), test_labels[\"label\"]\n",
        "  table_pred =  pd.read_csv('/content/Data/' + dataset_name + '/' + fold + '/pred_val.csv')\n",
        "  labels = table_pred[\"label\"]\n",
        "  methods = table_pred\n",
        "  methods = table_pred.drop('label', axis=1)\n",
        "  methods = methods.drop('Unnamed: 0', axis=1)\n",
        "  methods=methods.drop('Unnamed: 0.1', axis=1)\n",
        "  D = compute_pairwise_diversity_matrix(labels.to_numpy(), methods.to_numpy(), double_fault)\n",
        "  D_prime = np.triu(D)\n",
        "  z = linkage(D_prime,'average')\n",
        "  distancias = z[-40:,2]\n",
        "  max_d = max(distancias)+0.1\n",
        "  min_d = 0.0\n",
        "  lista_distancias = np.sort(distancias)[::-1]\n",
        "  print(\"threshould of dendrogram rounded\" + fold +\": \",round(0.7*max(z[:,2]),3))\n",
        "  Elbow_method_graph(z,40,fold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AiPxZoDMNrjs"
      },
      "outputs": [],
      "source": [
        "def stackingD(k,stacking,metric,fold):\n",
        "    train_df = pd.read_csv('/content/content/Data/'+dataset_name+'/'+fold+'/prob_train.csv').dropna()\n",
        "    val_df = pd.read_csv('/content/content/Data/'+dataset_name+'/'+fold+'/prob_val.csv').dropna()\n",
        "    test_df = pd.read_csv('/content/content/Data/'+dataset_name+'/'+fold+'/prob_test.csv').dropna()\n",
        "    probas_val, labels_val = val_df.drop(columns=[\"Unnamed: 0\",\"label\"]), val_df[\"label\"]\n",
        "    probas_test, labels_test = test_df.drop(columns=[\"Unnamed: 0\",\"label\"]), test_df[\"label\"]\n",
        "    results = []\n",
        "    table_pred = pd.read_csv('/content/content/Data/' + dataset_name + '/' + fold + '/pred_val.csv')\n",
        "    table = table_pred.drop(columns=['Unnamed: 0','Unnamed: 0.1','label'])\n",
        "    label_list=np.array(table_pred['label'])\n",
        "    for column in table.columns:\n",
        "      pred_list = np.array(table[column])\n",
        "      results.append([metric(label_list,pred_list),column])\n",
        "    resuts = results.sort(reverse=True)\n",
        "    df_results=pd.DataFrame(results,columns=['col0','col1'])\n",
        "    if k == 1:\n",
        "      lista_2 = fcluster(z, max_d , criterion='distance')\n",
        "    elif k == 40:\n",
        "      lista_2 = fcluster(z, min_d , criterion='distance')\n",
        "    else:\n",
        "      lista_2 = fcluster(z, lista_distancias[k-1] , criterion='distance')\n",
        "    df = pd.DataFrame(data = {'col0': lista_2, 'col1': lista_1})\n",
        "    df = df.merge(df_results, on='col1')\n",
        "    df = df.sort_values(by='col0_y', ascending=False)\n",
        "    models_D=[]\n",
        "    names=[]\n",
        "    final_dataframe=pd.DataFrame(columns=['k','metric','models'])\n",
        "    window = df.groupby('col0_x').max()\n",
        "    result = window.sort_values(by='col0_y', ascending=False)\n",
        "    models_D = list(result['col1'])\n",
        "    names=str(models_D[0])\n",
        "    for item in models_D[1:]:\n",
        "      names += '|'+item\n",
        "    results_D = np.zeros(len(models_D))\n",
        "    sum=0.0\n",
        "    for idx_alg, fe in enumerate(models_D):\n",
        "      X_val, X_test, cols = filter_df_train_test(probas_val, probas_test, names)\n",
        "      X_val, X_test = filter_collinearity(X_val, X_test)\n",
        "      stacking.fit(X_val, labels_val)\n",
        "      y_pred = stacking.predict(X_test)\n",
        "      results_D[idx_alg] = round(metric(labels_test, y_pred),3)\n",
        "    return k,round(results_D.mean(),3),models_D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dan9bAEzwNEj"
      },
      "outputs": [],
      "source": [
        "def saving_stacking_D(stacking, metric):\n",
        "  final_dataframe=pd.DataFrame(columns=['k','metric','models'])\n",
        "  for fold in [\"F1\", \"F2\", \"F3\", \"F4\", \"F5\",\"F6\", \"F7\", \"F8\", \"F9\", \"F10\"]:\n",
        "    for k in range(1,41):\n",
        "      a,b,c = stackingD(k,stacking,metric,fold)\n",
        "      final_dataframe.loc[k-1] = [a,b,c]\n",
        "      final_dataframe = final_dataframe.iloc[0:40]\n",
        "      final_dataframe.to_csv('/content/Data/' + dataset_name + '/'+ fold +'/'+ conditions_name_metric(metric) +\n",
        "                             '/final_dataframe_'+ conditions_name_stacking(stacking) +'.csv')\n",
        "  data_final = pd.DataFrame()\n",
        "  for fold in [\"F1\", \"F2\", \"F3\", \"F4\", \"F5\",\"F6\", \"F7\", \"F8\", \"F9\", \"F10\"]:\n",
        "    df = pd.read_csv('/content/Data/'+ dataset_name + '/'+fold+'/'+ conditions_name_metric(metric) +\n",
        "                     '/final_dataframe_'+ conditions_name_stacking(stacking) +'.csv')\n",
        "    df = df.sort_values(by=['metric'],ascending=False).head(1)\n",
        "    df['fold'] = fold\n",
        "    data_final = pd.concat([data_final,df])\n",
        "  data_final = data_final.drop(columns=['Unnamed: 0'])\n",
        "  data_final.reset_index(inplace=False)\n",
        "  return data_final.to_csv('/content/Data/' + dataset_name + '_' + conditions_name_metric(metric) +\n",
        "                           '_final_dataframe_all_'+ conditions_name_stacking(stacking) +'.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dl-E8aCHw2fz"
      },
      "outputs": [],
      "source": [
        "for metrica in accuracy_score, precision_score, recall_score, f1_score:\n",
        "  for stacking_algorithm in stackingLR[1], stackingRF[1], stackingNB[1]:\n",
        "    stacking, metric = stacking_algorithm, metrica\n",
        "    saving_stacking_D(stacking, metric)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "6jNBqH-tnRp2",
        "YzLBFKM1nTC6",
        "O9Zaiv9upV_-",
        "M06vnWNkD1jk",
        "GDpAxmgy7QUW"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
